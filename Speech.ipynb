{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OqT0WsSYSLb"
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "\n",
    "def identity_preprocess(str):\n",
    "  return str\n",
    "\n",
    "def readfile(path,preprocess=identity_preprocess):\n",
    "  processed_txt=[]\n",
    "  f = open(path, \"r\")\n",
    "  for line in f:\n",
    "    processed_txt= processed_txt + preprocess(line)\n",
    "  return processed_txt \n",
    "\n",
    "def tokenize(s):\n",
    "    s = s.strip().lower()\n",
    "    s = ''.join(c if c.isalpha() else ' ' for c in s)\n",
    "    # We replace all non-alpha characters with ' '\n",
    "    s = s.replace('\\n',' ')\n",
    "    s = s.split()\n",
    "    return s\n",
    "  \n",
    "# TODO: experiment with ntk tokenizers \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1574168112504,
     "user": {
      "displayName": "Dorothea Kalliora",
      "photoUrl": "",
      "userId": "17412342597228224634"
     },
     "user_tz": -120
    },
    "id": "YXntX-DgfvSF",
    "outputId": "19b454d9-ca2c-4be2-cb8c-bfe654403163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64183\n",
      "7072\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "\n",
    "text = readfile('./data/36-0.txt',tokenize)\n",
    "print(len(text))\n",
    "word_corpus = list(set(text))\n",
    "print(len(word_corpus))\n",
    "# Convert list of words to list of chars, get unique chars with set\n",
    "alphabet = list(set([c for word in word_corpus for c in word]))\n",
    "print(len(alphabet))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "\n",
    "def create_syms(alphabet):\n",
    "    f = open(\"./chars.syms\",\"w+\")\n",
    "    f.write(f'<epsilon>     0\\n')  #for <epsilon> index 0\n",
    "    for i in range(len(alphabet)):\n",
    "        f.write(f'{alphabet[i]}     {i+50}\\n')  #for other characters index i+50\n",
    "        \n",
    "create_syms(alphabet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5\n",
    "# We must create FST using shell\n",
    "\n",
    "# arc format: src dest ilabel olabel [weight]\n",
    "# final state format: state [weight]\n",
    "# lines may occur in any order except initial state must be first line\n",
    "# unspecified weights default to 0.0 (for the library-default Weight type) \n",
    "\n",
    "f = open('lev.fst',\"w+\")\n",
    "\n",
    "def format_arc(src,dst,src_sym,dst_sym,w,f,acceptor=False):\n",
    "    if not acceptor:\n",
    "        f.write(\"{} {} {} {} {} \\n\".format(src,dst,src_sym,dst_sym,w))\n",
    "    else:\n",
    "        f.write(\"{} {} {} \\n\".format(src,dst,src_sym))\n",
    "letters =  alphabet\n",
    "\n",
    "for i in range(0, len(letters)):\n",
    "    format_arc(src=0, dst=0, src_sym=\"<epsilon>\", dst_sym=letters[i], w=1,f=f)\n",
    "    format_arc(src=0, dst=0, src_sym=letters[i], dst_sym=letters[i], w=0,f=f)\n",
    "    format_arc(src=0, dst=0, src_sym=letters[i], dst_sym=\"<epsilon>\", w=1,f=f)\n",
    "    for j in range(0, len(letters)):\n",
    "        if(j!=i):\n",
    "            format_arc(src=0, dst=0, src_sym=letters[i], dst_sym=letters[j], w=1,f=f)   \n",
    "f.write('0\\n')\n",
    "f.close()\n",
    "    \n",
    "\n",
    "#TODO: change the edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fstcompile --isymbols=chars.syms --osymbols=chars.syms  lev.fst lev.bin.fst\n",
    "!fstdraw --isymbols=chars.syms --osymbols=chars.syms -portrait lev.bin.fst | dot -Tjpg >lev.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An acceptor is a finite automaton where each transition has a label and possibly a weight. In this library, an acceptor is represented as a transducer with the input and output label of each transition being equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6\n",
    "\n",
    "f = open(\"acceptor.fst\",\"w+\")\n",
    "s = 0\n",
    "final_states = []\n",
    "word_corpus_cut = word_corpus\n",
    "for word in word_corpus_cut:\n",
    "    format_arc(0,s+1,word[0],_,_,f,acceptor=True)\n",
    "    s += 1\n",
    "    for letter in word[1:]:\n",
    "        format_arc(s,s+1,letter,_, _,f,acceptor=True)\n",
    "        s += 1\n",
    "    final_states.append(s)\n",
    "    \n",
    "for state in final_states:\n",
    "    f.write(f'{state}\\n')\n",
    "    \n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fstcompile --isymbols=chars.syms --osymbols=chars.syms --acceptor acceptor.fst acc.bin.fst\n",
    "#!fstdraw --isymbols=chars.syms --osymbols=chars.syms -portrait rosebud.bin1.fst | dot -Tjpg >acc.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6b\n",
    "\n",
    "!fstrmepsilon acc.bin.fst eps.fst\n",
    "#!fstdraw --isymbols=chars.syms --osymbols=chars.syms -portrait eps.fst | dot -Tjpg >dfa_rmepsilon.jpg\n",
    "\n",
    "!fstdeterminize eps.fst det.fst\n",
    "#!fstdraw --isymbols=chars.syms --osymbols=chars.syms -portrait det.fst | dot -Tjpg >dfa_determinize.jpg\n",
    "\n",
    "!fstminimize det.fst mini.fst\n",
    "#!fstdraw --isymbols=chars.syms --osymbols=chars.syms -portrait mini.fst | dot -Tjpg >dfa_minimize.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7\n",
    "#mini.fst - lev.fst\n",
    "\n",
    "!fstarcsort --sort_type=olabel lev.bin.fst lev_sorted.bin.fst\n",
    "!fstarcsort --sort_type=ilabel mini.fst mini.fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fstcompose  lev_sorted.bin.fst mini.fst composed.bin.fst\n",
    "#!fstdraw --isymbols=chars.syms --osymbols=chars.syms -portrait composed.bin.fst | dot -Tjpg >com.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open(\"input.fst\",\"w+\")\n",
    "s = 0\n",
    "final_states = []\n",
    "word_corpus_cut = ['cit']\n",
    "for word in word_corpus_cut:\n",
    "    format_arc(0,s+1,word[0],word[0],0,f,acceptor=True)\n",
    "    s += 1\n",
    "    for letter in word[1:]:\n",
    "        format_arc(s,s+1,letter, letter, 0,f,acceptor=True)\n",
    "        s += 1\n",
    "    final_states.append(s)\n",
    "    \n",
    "for state in final_states:\n",
    "    f.write(f'{state}\\n')\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fstcompile  --isymbols=chars.syms --osymbols=chars.syms  --acceptor input.fst I.bin.fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fstarcsort --sort_type=ilabel composed.bin.fst s_composed.bin.fst \n",
    "!fstarcsort --sort_type=olabel I.bin.fst s_I.bin.fst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pit"
     ]
    }
   ],
   "source": [
    "!fstcompose s_I.bin.fst s_composed.bin.fst |fstshortestpath --nshortest=1 \\\n",
    "| fstrmepsilon |  fsttopsort |fstprint -isymbols=chars.syms  -osymbols=chars.syms\\\n",
    "| cut -f4 | grep -v \"<epsilon>\" |head -n -1 | tr -d '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\tc\tp\t1\r\n",
      "1\t2\ti\ti\r\n",
      "2\t3\tt\tt\r\n",
      "3\r\n"
     ]
    }
   ],
   "source": [
    "!fstcompose s_I.bin.fst s_composed.bin.fst |fstshortestpath --nshortest=1   \\\n",
    "| fstrmepsilon |  fsttopsort |fstprint -isymbols=chars.syms  -osymbols=chars.syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/georgepar/python-lab/master/spell_checker_test_set -P ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contented', 'contented', 'contented', 'contented']\n",
      "['contenpted', 'contende', 'contended', 'contentid']\n",
      "270\n",
      "270\n",
      "[161, 251, 84, 82, 47, 119, 260, 257, 52, 232, 108, 222, 45, 100, 193, 143, 261, 177, 42, 121]\n"
     ]
    }
   ],
   "source": [
    "# Step 8:\n",
    "import random\n",
    "\n",
    "file = open('./data/spell_checker_test_set',\"r\")\n",
    "y_test = []\n",
    "X_test = []\n",
    "for line in file:\n",
    "    [y,X] = line.split(':')\n",
    "    X = X.split()\n",
    "    for word in X:\n",
    "        X_test.append(word)\n",
    "        y_test.append(y)\n",
    "\n",
    "print(y_test[0:4])\n",
    "print(X_test[0:4])\n",
    "print(len(y_test))\n",
    "print(len(X_test))\n",
    "idxs = random.sample(range(0, len(y_test)), 20)\n",
    "print(idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Y,X):\n",
    "    for y,x in zip(Y,X):\n",
    "        \n",
    "        f = open(\"input.fst\",\"w\")\n",
    "        s = 0\n",
    "        word = x\n",
    "        final_states = []\n",
    "        format_arc(0,s+1,word[0],word[0],0,f,acceptor=True)\n",
    "        s += 1\n",
    "        for letter in word[1:]:\n",
    "            format_arc(s,s+1,letter, letter, 0,f,acceptor=True)\n",
    "            s += 1\n",
    "        final_states.append(s)\n",
    "\n",
    "        for state in final_states:\n",
    "            f.write(f'{state}\\n')\n",
    "        f.close()    \n",
    "        !fstcompile  --isymbols=chars.syms --osymbols=chars.syms  --acceptor input.fst I.bin.fst\n",
    "        !fstarcsort --sort_type=ilabel composed.bin.fst s_composed.bin.fst \n",
    "        !fstarcsort --sort_type=olabel I.bin.fst s_I.bin.fst \n",
    "        prediction = !fstcompose s_I.bin.fst s_composed.bin.fst |fstshortestpath --nshortest=1 \\\n",
    "        | fstrmepsilon |  fsttopsort |fstprint -isymbols=chars.syms  -osymbols=chars.syms\\\n",
    "        | cut -f4 | grep -v \"<epsilon>\" |head -n -1 | tr -d '\\n' \n",
    "        print(\"Wrong = \",x,\"-- Correct = \",y,\"-- Prediction = \",prediction[0])\n",
    "        correct_pred=0\n",
    "        if y == prediction[0]:\n",
    "            correct_pred+=1\n",
    "    print(f\"Accuracy:{correct_pred/len(Y)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong =  perpul -- Correct =  purple -- Prediction =  peril\n",
      "Wrong =  oppossitte -- Correct =  opposite -- Prediction =  opposite\n",
      "Wrong =  southen -- Correct =  southern -- Prediction =  southern\n",
      "Wrong =  undersand -- Correct =  understand -- Prediction =  understand\n",
      "Wrong =  avaible -- Correct =  available -- Prediction =  audible\n",
      "Wrong =  latiest -- Correct =  latest -- Prediction =  latest\n",
      "Wrong =  adres -- Correct =  address -- Prediction =  are\n",
      "Wrong =  curtians -- Correct =  curtains -- Prediction =  martians\n",
      "Wrong =  necassary -- Correct =  necessary -- Prediction =  necessary\n",
      "Wrong =  extreamly -- Correct =  extremely -- Prediction =  extremely\n",
      "Wrong =  beetween -- Correct =  between -- Prediction =  between\n",
      "Wrong =  carrer -- Correct =  career -- Prediction =  carrier\n",
      "Wrong =  buiscits -- Correct =  biscuits -- Prediction =  biscuits\n",
      "Wrong =  desicate -- Correct =  desiccate -- Prediction =  delicate\n",
      "Wrong =  accesing -- Correct =  accessing -- Prediction =  accepting\n",
      "Wrong =  chalenges -- Correct =  challenges -- Prediction =  changes\n",
      "Wrong =  liaision -- Correct =  liaison -- Prediction =  passion\n",
      "Wrong =  scisors -- Correct =  scissors -- Prediction =  sailors\n",
      "Wrong =  biscutes -- Correct =  biscuits -- Prediction =  biscuits\n",
      "Wrong =  perhapse -- Correct =  perhaps -- Prediction =  perhaps\n",
      "Accuracy:0.05%\n"
     ]
    }
   ],
   "source": [
    "X_rand = [X_test[i] for i in idxs]\n",
    "Y_rand = [y_test[i] for i in idxs]\n",
    "predict(Y_rand,X_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Speech.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
