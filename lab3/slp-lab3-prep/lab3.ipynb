{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">Επεξεργασία Φωνής και Φυσικής Γλώσσας</h1>\n",
    "<h2 align = \"center\">3ο Εργαστήριο (Προπαρασκευή) </h2>\n",
    "<h3 align = \"center\">Sentiment Analysis </h3>\n",
    "<h3 align = \"center\"> Θεoδωρόπουλος Νικήτας -03115185</h3>\n",
    "<h3 align = \"center\"> Καλλιώρα Δωροθέα - 03115176</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings...\n",
      "Loaded word embeddings from cache.\n",
      "\n",
      "\u001b[1mQuestion 1:\u001b[0m\n",
      "\n",
      "\n",
      "Labels for 10 first training examples:\n",
      "\n",
      "Original: ['positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive']\n",
      "\n",
      "After LabelEncoder: [1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 2:\u001b[0m\n",
      "\n",
      "Tokenized sample:\n",
      "['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '``', 'conan', '``', 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['the', 'gorgeously', 'elaborate', 'continuation', 'of', '``', 'the', 'lord', 'of', 'the', 'rings', '``', 'trilogy', 'is', 'so', 'huge', 'that', 'a', 'column', 'of', 'words', 'can', 'not', 'adequately', 'describe', 'co-writer/director', 'peter', 'jackson', \"'s\", 'expanded', 'vision', 'of', 'j', '.', 'r', '.', 'r', '.', 'tolkien', \"'s\", 'middle-earth', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['effective', 'but', 'too-tepid', 'biopic']\n",
      "\n",
      "Tokenized sample:\n",
      "['if', 'you', 'sometimes', 'like', 'to', 'go', 'to', 'the', 'movies', 'to', 'have', 'fun', ',', 'wasabi', 'is', 'a', 'good', 'place', 'to', 'start', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['emerges', 'as', 'something', 'rare', ',', 'an', 'issue', 'movie', 'that', \"'s\", 'so', 'honest', 'and', 'keenly', 'observed', 'that', 'it', 'does', \"n't\", 'feel', 'like', 'one', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['the', 'film', 'provides', 'some', 'great', 'insight', 'into', 'the', 'neurotic', 'mindset', 'of', 'all', 'comics', '--', 'even', 'those', 'who', 'have', 'reached', 'the', 'absolute', 'top', 'of', 'the', 'game', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['offers', 'that', 'rare', 'combination', 'of', 'entertainment', 'and', 'education', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['perhaps', 'no', 'picture', 'ever', 'made', 'has', 'more', 'literally', 'showed', 'that', 'the', 'road', 'to', 'hell', 'is', 'paved', 'with', 'good', 'intentions', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['steers', 'turns', 'in', 'a', 'snappy', 'screenplay', 'that', 'curls', 'at', 'the', 'edges', ';', 'it', \"'s\", 'so', 'clever', 'you', 'want', 'to', 'hate', 'it', '.', 'but', 'he', 'somehow', 'pulls', 'it', 'off', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different', 'slice', 'of', 'asian', 'cinema', '.']\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 3:\u001b[0m\n",
      "\n",
      "Original sample:\n",
      "an utterly compelling 'who wrote it' in which the reputation of the most famous author who ever lived comes into question .\n",
      "\n",
      "Transformed sample:\n",
      "(array([    30,  14306,   8538, 400001,    837,     21,     58,      7,\n",
      "           43,      1,   3148,      4,      1,     97,   1614,   1716,\n",
      "           39,    662,   1578,    935,     76,    996,      3,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0]), 1, 23)\n",
      "\n",
      "Original sample:\n",
      "illuminating if overly talky documentary .\n",
      "\n",
      "Transformed sample:\n",
      "(array([31742,    84, 11014, 98927,  3831,     3,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0]), 1, 6)\n",
      "\n",
      "Original sample:\n",
      "a masterpiece four years in the making .\n",
      "\n",
      "Transformed sample:\n",
      "(array([    8, 15024,   134,    83,     7,     1,   434,     3,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0]), 1, 8)\n",
      "\n",
      "Original sample:\n",
      "the movie's ripe , enrapturing beauty will tempt those willing to probe its inscrutable mysteries .\n",
      "\n",
      "Transformed sample:\n",
      "(array([     1,   1006,     10,  13712,      2, 400001,   4283,     44,\n",
      "        38664,    156,   2209,      5,   3616,     48,  59907,  14934,\n",
      "            3,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0]), 1, 17)\n",
      "\n",
      "Original sample:\n",
      "offers a breath of the fresh air of true sophistication .\n",
      "\n",
      "Transformed sample:\n",
      "(array([ 1729,     8,  8354,     4,     1,  1904,   326,     4,  1447,\n",
      "       20664,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0]), 1, 11)\n",
      "\n",
      "BaselineDNN(\n",
      "  (embeddings): Embedding(400002, 50)\n",
      "  (lin1): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (lin2): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n",
      " [========================================] ...Epoch 1, Loss: 0.7325\n",
      " Epoch 1, Total loss: 0.6720\n",
      "\n",
      " [========================================] ...Epoch 2, Loss: 0.4846\n",
      " Epoch 2, Total loss: 0.6326\n",
      "\n",
      " [========================================] ...Epoch 3, Loss: 0.2357\n",
      " Epoch 3, Total loss: 0.6071\n",
      "\n",
      " [========================================] ...Epoch 4, Loss: 0.3021\n",
      " Epoch 4, Total loss: 0.5921\n",
      "\n",
      " [========================================] ...Epoch 5, Loss: 0.5266\n",
      " Epoch 5, Total loss: 0.5832\n",
      "\n",
      " [========================================] ...Epoch 6, Loss: 0.5190\n",
      " Epoch 6, Total loss: 0.5789\n",
      "\n",
      " [========================================] ...Epoch 7, Loss: 0.6024\n",
      " Epoch 7, Total loss: 0.5752\n",
      "\n",
      " [========================================] ...Epoch 8, Loss: 0.4330\n",
      " Epoch 8, Total loss: 0.5729\n",
      "\n",
      " [========================================] ...Epoch 9, Loss: 0.6631\n",
      " Epoch 9, Total loss: 0.5713\n",
      "\n",
      " [========================================] ...Epoch 10, Loss: 0.4705\n",
      " Epoch 10, Total loss: 0.5699\n",
      "\n",
      " [========================================] ...Epoch 11, Loss: 0.6829\n",
      " Epoch 11, Total loss: 0.5686\n",
      "\n",
      " [========================================] ...Epoch 12, Loss: 0.6762\n",
      " Epoch 12, Total loss: 0.5672\n",
      "\n",
      " [========================================] ...Epoch 13, Loss: 0.6167\n",
      " Epoch 13, Total loss: 0.5659\n",
      "\n",
      " [========================================] ...Epoch 14, Loss: 0.3577\n",
      " Epoch 14, Total loss: 0.5648\n",
      "\n",
      " [========================================] ...Epoch 15, Loss: 0.5596\n",
      " Epoch 15, Total loss: 0.5641\n",
      "\n",
      " [========================================] ...Epoch 16, Loss: 0.5442\n",
      " Epoch 16, Total loss: 0.5633\n",
      "\n",
      " [========================================] ...Epoch 17, Loss: 0.5196\n",
      " Epoch 17, Total loss: 0.5623\n",
      "\n",
      " [========================================] ...Epoch 18, Loss: 0.6636\n",
      " Epoch 18, Total loss: 0.5611\n",
      "\n",
      " [========================================] ...Epoch 19, Loss: 0.8110\n",
      " Epoch 19, Total loss: 0.5605\n",
      "\n",
      " [========================================] ...Epoch 20, Loss: 0.5898\n",
      " Epoch 20, Total loss: 0.5596\n",
      "\n",
      " [========================================] ...Epoch 21, Loss: 0.2125\n",
      " Epoch 21, Total loss: 0.5588\n",
      "\n",
      " [========================================] ...Epoch 22, Loss: 0.5354\n",
      " Epoch 22, Total loss: 0.5582\n",
      "\n",
      " [========================================] ...Epoch 23, Loss: 0.6036\n",
      " Epoch 23, Total loss: 0.5567\n",
      "\n",
      " [========================================] ...Epoch 24, Loss: 0.2398\n",
      " Epoch 24, Total loss: 0.5565\n",
      "\n",
      " [========================================] ...Epoch 25, Loss: 0.7061\n",
      " Epoch 25, Total loss: 0.5559\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================================] ...Epoch 26, Loss: 0.5507\n",
      " Epoch 26, Total loss: 0.5551\n",
      "\n",
      " [========================================] ...Epoch 27, Loss: 0.4632\n",
      " Epoch 27, Total loss: 0.5544\n",
      "\n",
      " [========================================] ...Epoch 28, Loss: 0.5494\n",
      " Epoch 28, Total loss: 0.5535\n",
      "\n",
      " [========================================] ...Epoch 29, Loss: 0.4481\n",
      " Epoch 29, Total loss: 0.5529\n",
      "\n",
      " [========================================] ...Epoch 30, Loss: 0.2143\n",
      " Epoch 30, Total loss: 0.5520\n",
      "\n",
      " [========================================] ...Epoch 31, Loss: 0.4616\n",
      " Epoch 31, Total loss: 0.5517\n",
      "\n",
      " [========================================] ...Epoch 32, Loss: 0.2198\n",
      " Epoch 32, Total loss: 0.5505\n",
      "\n",
      " [========================================] ...Epoch 33, Loss: 0.6835\n",
      " Epoch 33, Total loss: 0.5504\n",
      "\n",
      " [========================================] ...Epoch 34, Loss: 0.8967\n",
      " Epoch 34, Total loss: 0.5494\n",
      "\n",
      " [========================================] ...Epoch 35, Loss: 0.4445\n",
      " Epoch 35, Total loss: 0.5487\n",
      "\n",
      " [========================================] ...Epoch 36, Loss: 0.2427\n",
      " Epoch 36, Total loss: 0.5485\n",
      "\n",
      " [========================================] ...Epoch 37, Loss: 0.3499\n",
      " Epoch 37, Total loss: 0.5475\n",
      "\n",
      " [========================================] ...Epoch 38, Loss: 0.7959\n",
      " Epoch 38, Total loss: 0.5470\n",
      "\n",
      " [========================================] ...Epoch 39, Loss: 0.4448\n",
      " Epoch 39, Total loss: 0.5467\n",
      "\n",
      " [========================================] ...Epoch 40, Loss: 0.7064\n",
      " Epoch 40, Total loss: 0.5461\n",
      "\n",
      " [========================================] ...Epoch 41, Loss: 0.9699\n",
      " Epoch 41, Total loss: 0.5454\n",
      "\n",
      " [========================================] ...Epoch 42, Loss: 0.4542\n",
      " Epoch 42, Total loss: 0.5449\n",
      "\n",
      " [========================================] ...Epoch 43, Loss: 0.6830\n",
      " Epoch 43, Total loss: 0.5443\n",
      "\n",
      " [========================================] ...Epoch 44, Loss: 0.3817\n",
      " Epoch 44, Total loss: 0.5438\n",
      "\n",
      " [========================================] ...Epoch 45, Loss: 0.2928\n",
      " Epoch 45, Total loss: 0.5431\n",
      "\n",
      " [========================================] ...Epoch 46, Loss: 0.3478\n",
      " Epoch 46, Total loss: 0.5429\n",
      "\n",
      " [========================================] ...Epoch 47, Loss: 0.4753\n",
      " Epoch 47, Total loss: 0.5422\n",
      "\n",
      " [========================================] ...Epoch 48, Loss: 0.3802\n",
      " Epoch 48, Total loss: 0.5416\n",
      "\n",
      " [========================================] ...Epoch 49, Loss: 0.5498\n",
      " Epoch 49, Total loss: 0.5409\n",
      "\n",
      " [========================================] ...Epoch 50, Loss: 0.4350\n",
      " Epoch 50, Total loss: 0.5406\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 10, Classification Report:\u001b[0m\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.73      0.71       331\n",
      "         1.0       0.72      0.69      0.70       331\n",
      "\n",
      "    accuracy                           0.71       662\n",
      "   macro avg       0.71      0.71      0.71       662\n",
      "weighted avg       0.71      0.71      0.71       662\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 10, Plot:\u001b[0m\n",
      "\n",
      "Figure(800x800)\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/MR_50_loss.png?modified=12345678\" width = \"600\" height = auto;>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings...\n",
      "Loaded word embeddings from cache.\n",
      "\n",
      "\u001b[1mQuestion 1:\u001b[0m\n",
      "\n",
      "\n",
      "Labels for 10 first training examples:\n",
      "\n",
      "Original: ['neutral' 'neutral' 'negative' 'neutral' 'positive' 'negative' 'neutral'\n",
      " 'neutral' 'neutral' 'neutral']\n",
      "\n",
      "After LabelEncoder: [1 1 0 1 2 0 1 1 1 1]\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 2:\u001b[0m\n",
      "\n",
      "Tokenized sample:\n",
      "['@', 'SeeMonterey', 'LOST', '-', 'Sony', 'cell', 'phone', 'with', 'holiday', 'photos', '.', 'Early', 'Fri', 'morning', ',', 'Montreal', 'transit', 'plaza', 'or', 'no', '.', '13', 'bus', 'to', 'airport', '.', 'REWARD', '!', 'Plz', 'RT', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['@', 'PersonaSoda', 'well', 'yeah', ',', 'that', \"'s\", 'third', 'parties', '.', 'Sony', 'itself', 'is', \"n't\", 'putting', 'out', 'actual', 'games', 'for', 'it', '.', 'It', \"'s\", 'got', '1-2', 'yrs', 'of', '3rd', 'party', 'support', 'left', '.']\n",
      "\n",
      "Tokenized sample:\n",
      "['Sony', 'rewards', 'app', 'is', 'like', 'a', 'lot', 'of', '19', 'y.o', 'female', 'singers', 'and', 'a', 'non', 'retro', 'sale', '.', '2nd', 'one', 'with', 'no', 'info']\n",
      "\n",
      "Tokenized sample:\n",
      "['@', 'fakethom', 'Have', 'android', 'tab', 'and', 'do', \"n't\", 'use', 'phone', 'much', ',', 'in', 'fact', 'very', 'little', '.', 'May', 'go', 'the', 'Sony', 'route', 'then', ':', '-', ')']\n",
      "\n",
      "Tokenized sample:\n",
      "['Finally', 'I', 'get', 'my', 'ps4', 'back', 'I', 'sent', 'it', 'to', 'Sony', 'cause', 'my', 'HDMI', 'was', 'mess', 'up', 'now', 'I', 'can', 'play', 'MG', \"'s\", 'Tuesday', 'yeaaaaa', 'buddy']\n",
      "\n",
      "Tokenized sample:\n",
      "['@', 'AskPlayStation', 'Why', 'wo', \"n't\", 'u', 'guys', 'help', 'me', 'out', '?', '!', 'Im', 'calling', 'Sony', 'tomorrow', '!', 'I', 'want', 'help', 'but', 'the', '``', 'support', 'team', \"''\", '3', 'hours', 'of', 'tweeting', 'and', 'nothing']\n",
      "\n",
      "Tokenized sample:\n",
      "['Sony', \"'s\", '1st', 'teaser', 'package', 'for', 'the', 'launch', 'of', 'the', 'original', 'Playstation', 'seems', 'to', 'feature', 'a', 'dominatrix', '?', 'https', ':', '//t.co/xbisCRkPL4', '#', 'MistressSophia']\n",
      "\n",
      "Tokenized sample:\n",
      "['#', 'tv', 'Ind', 'vs', 'SL', '3rd', 'Test', 'Day', '3', ':', 'Cricket', 'live', 'score', 'and', 'Sony', 'Six', 'live', 'streaming', 'info', ':', 'Watch', 'the', 'live', 'teleca', '...', 'http', ':', '//t.co/mUlHw4cN00', '#', 'Sony']\n",
      "\n",
      "Tokenized sample:\n",
      "['@', 'TruthInsider', '@', 'bertymufc', '@', 'gamerxone720', '@', 'PNF4LYFE', '@', 'Yanks2013', '@', 'VirtuaMe', 'Lol', 'it', \"'s\", 'all', 'about', 'Sony', 'Sony', 'Sony', ',', 'if', 'Sony', 'gave', 'Bj', \"'s\", 'u', 'be', 'the', '1st']\n",
      "\n",
      "Tokenized sample:\n",
      "['@', 'greencapt', 'Official', 'reason', ',', 'because', 'the', 'game', 'has', 'to', 'be', 'on', 'our', 'region', 'store', 'and', 'sony', 'wont', 'have', 'it', 'up', 'til', 'tuesday']\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 3:\u001b[0m\n",
      "\n",
      "Original sample:\n",
      "At least Sony will probably be selling it for cheap come Black Friday.\n",
      "\n",
      "Transformed sample:\n",
      "(array([400001,    339, 400001,     44,    966,     31,   1515,     21,\n",
      "           11,   5116,    327, 400001, 400001,      3,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0]), 1, 14)\n",
      "\n",
      "Original sample:\n",
      "@InnoBystander Might keep SONY monthly subs going beyond tomorrow....\n",
      "\n",
      "Transformed sample:\n",
      "(array([ 17528, 400001, 400001,    579, 400001,   3308,  16145,    223,\n",
      "         1516,   4003,    435,      3,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0]), 1, 12)\n",
      "\n",
      "Original sample:\n",
      "@tauriqmoosa Nope. Tomorrow. Wait... tomorrow's also when Sony breaks out the next bundle of PS+ freebies. Oh, what a LOVELY day!\n",
      "\n",
      "Transformed sample:\n",
      "(array([ 17528, 400001, 400001,      3, 400001,      3, 400001,    435,\n",
      "         4003,     10,     53,     62, 400001,   4574,     67,      1,\n",
      "          183,  16672,      4, 400001,  58977,      3, 400001,      2,\n",
      "          103,      8, 400001,    123,    806,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0]), 2, 29)\n",
      "\n",
      "Original sample:\n",
      "\"Uncharted 4: A Thief's End launches for PS4 in North America on March 18, 2016, Sony announced today.The latest game in the Naughty D...\"\n",
      "\n",
      "Transformed sample:\n",
      "(array([    29, 400001,    410,     46, 400001, 400001,     10, 400001,\n",
      "         8339,     11, 400001,      7, 400001, 400001,     14, 400001,\n",
      "          520,      2,  15464,      2, 400001,    458, 400001,    994,\n",
      "          187,      7,      1, 400001, 400001,    435,     28,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0]), 1, 31)\n",
      "\n",
      "Original sample:\n",
      "@kewldoode72 Will be interesting to see if Sony addresses the heat issues in the Z5 - it may have found a work around\n",
      "\n",
      "Transformed sample:\n",
      "(array([ 17528, 400001, 400001,     31,   4002,      5,    254,     84,\n",
      "       400001,   7803,      1,   1966,    616,      7,      1, 400001,\n",
      "           12,     21,    108,     34,    239,      8,    162,    205,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0,      0,      0,      0,      0,\n",
      "            0,      0,      0,      0]), 0, 24)\n",
      "\n",
      "BaselineDNN(\n",
      "  (embeddings): Embedding(400002, 50)\n",
      "  (lin1): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (lin2): Linear(in_features=100, out_features=3, bias=True)\n",
      ")\n",
      " [========================================] ...Epoch 1, Loss: 0.7462\n",
      " Epoch 1, Total loss: 0.9545\n",
      "\n",
      " [========================================] ...Epoch 2, Loss: 0.8951\n",
      " Epoch 2, Total loss: 0.9013\n",
      "\n",
      " [========================================] ...Epoch 3, Loss: 0.7419\n",
      " Epoch 3, Total loss: 0.8848\n",
      "\n",
      " [========================================] ...Epoch 4, Loss: 0.9639\n",
      " Epoch 4, Total loss: 0.8779\n",
      "\n",
      " [========================================] ...Epoch 5, Loss: 1.1605\n",
      " Epoch 5, Total loss: 0.8737\n",
      "\n",
      " [========================================] ...Epoch 6, Loss: 1.0491\n",
      " Epoch 6, Total loss: 0.8709\n",
      "\n",
      " [========================================] ...Epoch 7, Loss: 1.2214\n",
      " Epoch 7, Total loss: 0.8685\n",
      "\n",
      " [========================================] ...Epoch 8, Loss: 0.5196\n",
      " Epoch 8, Total loss: 0.8664\n",
      "\n",
      " [========================================] ...Epoch 9, Loss: 1.6037\n",
      " Epoch 9, Total loss: 0.8648\n",
      "\n",
      " [========================================] ...Epoch 10, Loss: 0.2008\n",
      " Epoch 10, Total loss: 0.8635\n",
      "\n",
      " [========================================] ...Epoch 11, Loss: 0.9400\n",
      " Epoch 11, Total loss: 0.8620\n",
      "\n",
      " [========================================] ...Epoch 12, Loss: 0.5421\n",
      " Epoch 12, Total loss: 0.8607\n",
      "\n",
      " [========================================] ...Epoch 13, Loss: 0.3661\n",
      " Epoch 13, Total loss: 0.8592\n",
      "\n",
      " [========================================] ...Epoch 14, Loss: 0.7972\n",
      " Epoch 14, Total loss: 0.8585\n",
      "\n",
      " [========================================] ...Epoch 15, Loss: 0.8723\n",
      " Epoch 15, Total loss: 0.8572\n",
      "\n",
      " [========================================] ...Epoch 16, Loss: 0.7571\n",
      " Epoch 16, Total loss: 0.8565\n",
      "\n",
      " [========================================] ...Epoch 17, Loss: 0.5596\n",
      " Epoch 17, Total loss: 0.8554\n",
      "\n",
      " [========================================] ...Epoch 18, Loss: 1.1103\n",
      " Epoch 18, Total loss: 0.8544\n",
      "\n",
      " [========================================] ...Epoch 19, Loss: 0.6701\n",
      " Epoch 19, Total loss: 0.8535\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================================] ...Epoch 20, Loss: 0.4122\n",
      " Epoch 20, Total loss: 0.8526\n",
      "\n",
      " [========================================] ...Epoch 21, Loss: 0.7355\n",
      " Epoch 21, Total loss: 0.8515\n",
      "\n",
      " [========================================] ...Epoch 22, Loss: 0.5790\n",
      " Epoch 22, Total loss: 0.8507\n",
      "\n",
      " [========================================] ...Epoch 23, Loss: 0.5301\n",
      " Epoch 23, Total loss: 0.8501\n",
      "\n",
      " [========================================] ...Epoch 24, Loss: 1.8924\n",
      " Epoch 24, Total loss: 0.8492\n",
      "\n",
      " [========================================] ...Epoch 25, Loss: 0.8946\n",
      " Epoch 25, Total loss: 0.8486\n",
      "\n",
      " [========================================] ...Epoch 26, Loss: 1.0273\n",
      " Epoch 26, Total loss: 0.8477\n",
      "\n",
      " [========================================] ...Epoch 27, Loss: 1.7486\n",
      " Epoch 27, Total loss: 0.8470\n",
      "\n",
      " [========================================] ...Epoch 28, Loss: 0.8211\n",
      " Epoch 28, Total loss: 0.8462\n",
      "\n",
      " [========================================] ...Epoch 29, Loss: 0.7959\n",
      " Epoch 29, Total loss: 0.8459\n",
      "\n",
      " [========================================] ...Epoch 30, Loss: 1.7832\n",
      " Epoch 30, Total loss: 0.8455\n",
      "\n",
      " [========================================] ...Epoch 31, Loss: 0.8326\n",
      " Epoch 31, Total loss: 0.8444\n",
      "\n",
      " [========================================] ...Epoch 32, Loss: 0.7202-----] ...Epoch 32, Loss: 0.5218\n",
      " Epoch 32, Total loss: 0.8439\n",
      "\n",
      " [========================================] ...Epoch 33, Loss: 0.9750\n",
      " Epoch 33, Total loss: 0.8429\n",
      "\n",
      " [========================================] ...Epoch 34, Loss: 0.3988\n",
      " Epoch 34, Total loss: 0.8427\n",
      "\n",
      " [========================================] ...Epoch 35, Loss: 0.9189\n",
      " Epoch 35, Total loss: 0.8421\n",
      "\n",
      " [========================================] ...Epoch 36, Loss: 0.7482\n",
      " Epoch 36, Total loss: 0.8417\n",
      "\n",
      " [========================================] ...Epoch 37, Loss: 0.9748\n",
      " Epoch 37, Total loss: 0.8409\n",
      "\n",
      " [========================================] ...Epoch 38, Loss: 0.3408\n",
      " Epoch 38, Total loss: 0.8404\n",
      "\n",
      " [========================================] ...Epoch 39, Loss: 0.4209\n",
      " Epoch 39, Total loss: 0.8400\n",
      "\n",
      " [========================================] ...Epoch 40, Loss: 0.5617\n",
      " Epoch 40, Total loss: 0.8394\n",
      "\n",
      " [========================================] ...Epoch 41, Loss: 0.986541, Loss: 0.750941, Loss: 1.0251\n",
      " Epoch 41, Total loss: 0.8386\n",
      "\n",
      " [========================================] ...Epoch 42, Loss: 0.5694\n",
      " Epoch 42, Total loss: 0.8381\n",
      "\n",
      " [========================================] ...Epoch 43, Loss: 0.584543, Loss: 0.585543, Loss: 0.5139\n",
      " Epoch 43, Total loss: 0.8378\n",
      "\n",
      " [========================================] ...Epoch 44, Loss: 0.522344, Loss: 1.0641-----] ...Epoch 44, Loss: 0.9675=--------------------] ...Epoch 44, Loss: 0.4126==================-------------------] ...Epoch 44, Loss: 1.049244, Loss: 0.761744, Loss: 0.6976-----] ...Epoch 44, Loss: 0.680444, Loss: 0.449744, Loss: 0.963344, Loss: 1.674844, Loss: 0.7039\n",
      " Epoch 44, Total loss: 0.8376\n",
      "\n",
      " [========================================] ...Epoch 45, Loss: 1.792545, Loss: 0.747145, Loss: 1.382145, Loss: 0.7489-----] ...Epoch 45, Loss: 1.413145, Loss: 0.562645, Loss: 1.417045, Loss: 0.918445, Loss: 0.630845, Loss: 0.701245, Loss: 0.552745, Loss: 0.656345, Loss: 0.467945, Loss: 0.903545, Loss: 0.955145, Loss: 0.6534\n",
      " Epoch 45, Total loss: 0.8367\n",
      "\n",
      " [========================================] ...Epoch 46, Loss: 0.529146, Loss: 1.008946, Loss: 0.822246, Loss: 0.8078-----] ...Epoch 46, Loss: 0.778746, Loss: 0.5873-----] ...Epoch 46, Loss: 0.633846, Loss: 0.6412-----] ...Epoch 46, Loss: 0.883546, Loss: 1.3797-----] ...Epoch 46, Loss: 0.8876---------------------] ...Epoch 46, Loss: 0.762846, Loss: 1.165446, Loss: 0.805146, Loss: 1.1665-----] ...Epoch 46, Loss: 0.708146, Loss: 0.915146, Loss: 1.7370-----] ...Epoch 46, Loss: 0.8939---------------------] ...Epoch 46, Loss: 0.4927====---------------------------------] ...Epoch 46, Loss: 1.0645: 0.770946, Loss: 0.805146, Loss: 0.499146, Loss: 1.011346, Loss: 0.7687-----] ...Epoch 46, Loss: 1.213446, Loss: 0.386446, Loss: 0.7767-----] ...Epoch 46, Loss: 0.6695---------------------] ...Epoch 46, Loss: 0.7008========-----------------------------] ...Epoch 46, Loss: 0.565746, Loss: 0.5827-----] ...Epoch 46, Loss: 0.740846, Loss: 1.132946, Loss: 0.703846, Loss: 0.462646, Loss: 0.966146, Loss: 0.718146, Loss: 0.656346, Loss: 0.550546, Loss: 0.950046, Loss: 0.470246, Loss: 1.062546, Loss: 1.112846, Loss: 1.686946, Loss: 0.5862=----] ...Epoch 46, Loss: 0.880746, Loss: 0.506546, Loss: 0.867846, Loss: 0.7578====-] ...Epoch 46, Loss: 0.458446, Loss: 0.701646, Loss: 1.1655\n",
      " Epoch 46, Total loss: 0.8362\n",
      "\n",
      " [========================================] ...Epoch 47, Loss: 0.408847, Loss: 1.145847, Loss: 0.9403-----] ...Epoch 47, Loss: 0.931647, Loss: 0.911747, Loss: 0.661347, Loss: 0.4386-----] ...Epoch 47, Loss: 0.731847, Loss: 0.5594-----] ...Epoch 47, Loss: 0.821747, Loss: 0.8276-----] ...Epoch 47, Loss: 0.626547, Loss: 0.626147, Loss: 1.724647, Loss: 0.876247, Loss: 1.2699-----] ...Epoch 47, Loss: 0.568647, Loss: 0.451147, Loss: 0.5355-----] ...Epoch 47, Loss: 0.560747, Loss: 0.9591-----] ...Epoch 47, Loss: 0.903347, Loss: 0.642247, Loss: 0.799347, Loss: 1.189847, Loss: 0.4407-----] ...Epoch 47, Loss: 0.8093---------------------] ...Epoch 47, Loss: 0.7317=====--------------------------------] ...Epoch 47, Loss: 0.887947, Loss: 0.609447, Loss: 0.5657-----] ...Epoch 47, Loss: 0.5673---------------------] ...Epoch 47, Loss: 0.715247, Loss: 0.6640-----] ...Epoch 47, Loss: 0.8519---------------------] ...Epoch 47, Loss: 0.601447, Loss: 0.899247, Loss: 1.101447, Loss: 0.420047, Loss: 0.5380-----] ...Epoch 47, Loss: 1.2146---------------------] ...Epoch 47, Loss: 0.649447, Loss: 0.5998-----] ...Epoch 47, Loss: 1.3463---------------------] ...Epoch 47, Loss: 0.9457===========--------------------------] ...Epoch 47, Loss: 0.962647, Loss: 0.7758-----] ...Epoch 47, Loss: 1.100547, Loss: 0.846847, Loss: 1.1235-----] ...Epoch 47, Loss: 0.585247, Loss: 0.921347, Loss: 0.575447, Loss: 0.743547, Loss: 1.383447, Loss: 1.570547, Loss: 0.6838-----] ...Epoch 47, Loss: 1.390047, Loss: 1.615047, Loss: 0.791747, Loss: 1.156047, Loss: 0.590047, Loss: 0.7535-----] ...Epoch 47, Loss: 1.088547, Loss: 0.871047, Loss: 0.860647, Loss: 0.938847, Loss: 1.242847, Loss: 0.5129-----] ...Epoch 47, Loss: 0.697147, Loss: 1.645547, Loss: 0.966847, Loss: 0.977947, Loss: 0.8113-----] ...Epoch 47, Loss: 0.6175============---------] ...Epoch 47, Loss: 0.484447, Loss: 1.0349-----] ...Epoch 47, Loss: 0.851247, Loss: 0.763647, Loss: 1.011647, Loss: 1.0477-----] ...Epoch 47, Loss: 1.069047, Loss: 0.512947, Loss: 0.6094-----] ...Epoch 47, Loss: 0.586147, Loss: 0.6106-----] ...Epoch 47, Loss: 1.244547, Loss: 1.087347, Loss: 0.839347, Loss: 0.581947, Loss: 0.6667==---] ...Epoch 47, Loss: 0.848947, Loss: 0.884347, Loss: 0.707247, Loss: 1.128847, Loss: 0.6568====-] ...Epoch 47, Loss: 0.5776====================-] ...Epoch 47, Loss: 1.320247, Loss: 1.2445====-] ...Epoch 47, Loss: 1.000247, Loss: 1.1840\n",
      " Epoch 47, Total loss: 0.8361\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================================] ...Epoch 48, Loss: 0.552248, Loss: 0.6186-----] ...Epoch 48, Loss: 0.421248, Loss: 0.911248, Loss: 0.649948, Loss: 0.4863-----] ...Epoch 48, Loss: 0.9271---------------------] ...Epoch 48, Loss: 0.299348, Loss: 0.5435-----] ...Epoch 48, Loss: 0.942248, Loss: 0.519548, Loss: 0.6991-----] ...Epoch 48, Loss: 0.553748, Loss: 1.0095-----] ...Epoch 48, Loss: 0.7197---------------------] ...Epoch 48, Loss: 0.759948, Loss: 0.6765-----] ...Epoch 48, Loss: 0.895048, Loss: 0.5351-----] ...Epoch 48, Loss: 0.5336---------------------] ...Epoch 48, Loss: 0.7301==-----------------------------------] ...Epoch 48, Loss: 0.5821: 0.3252..Epoch 48, Loss: 0.4326-------------] ...Epoch 48, Loss: 1.0373-----------------------------] ...Epoch 48, Loss: 0.642448, Loss: 1.4427-----] ...Epoch 48, Loss: 0.5153---------------------] ...Epoch 48, Loss: 1.0574==-----------------------------------] ...Epoch 48, Loss: 1.114448, Loss: 0.5226-----] ...Epoch 48, Loss: 0.6748---------------------] ...Epoch 48, Loss: 0.5486===----------------------------------] ...Epoch 48, Loss: 0.6965: 0.5642..Epoch 48, Loss: 1.268448, Loss: 0.3963-----] ...Epoch 48, Loss: 0.5830---------------------] ...Epoch 48, Loss: 0.631848, Loss: 0.9494-----] ...Epoch 48, Loss: 1.0363---------------------] ...Epoch 48, Loss: 1.1556====---------------------------------] ...Epoch 48, Loss: 0.6108: 0.9136..Epoch 48, Loss: 0.8982-------------] ...Epoch 48, Loss: 0.758648, Loss: 1.060948, Loss: 0.7671-----] ...Epoch 48, Loss: 0.319348, Loss: 0.6336-----] ...Epoch 48, Loss: 0.571848, Loss: 0.562648, Loss: 0.6347-----] ...Epoch 48, Loss: 0.9488---------------------] ...Epoch 48, Loss: 0.7543===========--------------------------] ...Epoch 48, Loss: 0.8452: 1.2552..Epoch 48, Loss: 0.5024-------------] ...Epoch 48, Loss: 1.533848, Loss: 0.8310-----] ...Epoch 48, Loss: 1.1066---------------------] ...Epoch 48, Loss: 0.670348, Loss: 0.7054-----] ...Epoch 48, Loss: 0.759548, Loss: 1.259248, Loss: 0.877848, Loss: 0.737948, Loss: 1.530348, Loss: 1.1469-----] ...Epoch 48, Loss: 0.884748, Loss: 0.4529-----] ...Epoch 48, Loss: 1.037648, Loss: 0.6866-----] ...Epoch 48, Loss: 0.6854---------------------] ...Epoch 48, Loss: 1.0241===============----------------------] ...Epoch 48, Loss: 0.384448, Loss: 1.191248, Loss: 0.6242-----] ...Epoch 48, Loss: 0.9532---------------------] ...Epoch 48, Loss: 0.642748, Loss: 0.6429-----] ...Epoch 48, Loss: 0.8961=--------------------] ...Epoch 48, Loss: 1.371648, Loss: 1.063748, Loss: 0.761048, Loss: 0.6791-----] ...Epoch 48, Loss: 0.486748, Loss: 0.4921-----] ...Epoch 48, Loss: 1.6037==-------------------] ...Epoch 48, Loss: 1.000448, Loss: 1.3048-----] ...Epoch 48, Loss: 0.9578==-------------------] ...Epoch 48, Loss: 0.955148, Loss: 0.640748, Loss: 1.116148, Loss: 0.390048, Loss: 1.570348, Loss: 0.670548, Loss: 0.589948, Loss: 1.149948, Loss: 0.8277-----] ...Epoch 48, Loss: 0.4880=====----------------] ...Epoch 48, Loss: 1.271148, Loss: 0.716448, Loss: 1.0994-----] ...Epoch 48, Loss: 0.9810======---------------] ...Epoch 48, Loss: 0.9362======================---------------] ...Epoch 48, Loss: 1.1288: 0.8985..Epoch 48, Loss: 0.997648, Loss: 0.928548, Loss: 0.4139-----] ...Epoch 48, Loss: 0.7649=========------------] ...Epoch 48, Loss: 0.4130=========================------------] ...Epoch 48, Loss: 0.7542: 0.805748, Loss: 0.5738-----] ...Epoch 48, Loss: 0.6947==========-----------] ...Epoch 48, Loss: 0.586048, Loss: 1.167348, Loss: 0.5165-----] ...Epoch 48, Loss: 1.2077===========----------] ...Epoch 48, Loss: 1.223648, Loss: 0.395948, Loss: 0.385548, Loss: 0.939548, Loss: 0.972348, Loss: 0.8369-----] ...Epoch 48, Loss: 0.8117=============--------] ...Epoch 48, Loss: 0.972748, Loss: 0.5675-----] ...Epoch 48, Loss: 0.6470=============--------] ...Epoch 48, Loss: 0.7403=============================--------] ...Epoch 48, Loss: 0.5705: 1.0250..Epoch 48, Loss: 0.808248, Loss: 1.245348, Loss: 0.492448, Loss: 1.003348, Loss: 0.414548, Loss: 0.548048, Loss: 1.078648, Loss: 0.886748, Loss: 0.874248, Loss: 1.396348, Loss: 0.872548, Loss: 0.8036=----] ...Epoch 48, Loss: 0.867948, Loss: 0.7628=----] ...Epoch 48, Loss: 0.531548, Loss: 0.759848, Loss: 0.958448, Loss: 0.7866===--] ...Epoch 48, Loss: 0.711248, Loss: 1.0919===--] ...Epoch 48, Loss: 0.6588===================--] ...Epoch 48, Loss: 0.422848, Loss: 0.484248, Loss: 1.397548, Loss: 0.5323====-] ...Epoch 48, Loss: 1.424148, Loss: 0.635948, Loss: 0.8366=====] ...Epoch 48, Loss: 0.662948, Loss: 0.6939=====] ...Epoch 48, Loss: 0.9382=====================] ...Epoch 48, Loss: 0.3186\n",
      " Epoch 48, Total loss: 0.8351\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================================] ...Epoch 49, Loss: 0.477549, Loss: 0.8171-----] ...Epoch 49, Loss: 0.3336---------------------] ...Epoch 49, Loss: 1.0821-------------------------------------] ...Epoch 49, Loss: 0.4857: 0.579549, Loss: 0.634549, Loss: 0.9322-----] ...Epoch 49, Loss: 1.215349, Loss: 0.6860-----] ...Epoch 49, Loss: 0.749749, Loss: 0.4962-----] ...Epoch 49, Loss: 0.8324---------------------] ...Epoch 49, Loss: 0.9296-------------------------------------] ...Epoch 49, Loss: 0.7063: 0.8868..Epoch 49, Loss: 1.1528-------------] ...Epoch 49, Loss: 0.858949, Loss: 0.876449, Loss: 0.8113-----] ...Epoch 49, Loss: 1.0182---------------------] ...Epoch 49, Loss: 0.8964-------------------------------------] ...Epoch 49, Loss: 0.8218: 0.9472..Epoch 49, Loss: 1.3140-------------] ...Epoch 49, Loss: 0.8201-----------------------------] ...Epoch 49, Loss: 0.492349, Loss: 0.447749, Loss: 0.8240-----] ...Epoch 49, Loss: 0.6134---------------------] ...Epoch 49, Loss: 0.539649, Loss: 0.8655-----] ...Epoch 49, Loss: 0.858349, Loss: 0.8939-----] ...Epoch 49, Loss: 0.5709---------------------] ...Epoch 49, Loss: 0.6766===----------------------------------] ...Epoch 49, Loss: 0.8934: 0.780749, Loss: 0.9136-----] ...Epoch 49, Loss: 0.5028---------------------] ...Epoch 49, Loss: 1.082049, Loss: 0.6199-----] ...Epoch 49, Loss: 0.8430---------------------] ...Epoch 49, Loss: 1.0326====---------------------------------] ...Epoch 49, Loss: 0.9734: 0.9346..Epoch 49, Loss: 1.0356-------------] ...Epoch 49, Loss: 0.648549, Loss: 1.1876-----] ...Epoch 49, Loss: 1.0337---------------------] ...Epoch 49, Loss: 1.0680=====--------------------------------] ...Epoch 49, Loss: 0.7456: 1.0917..Epoch 49, Loss: 0.6092-------------] ...Epoch 49, Loss: 0.9787-----------------------------] ...Epoch 49, Loss: 0.372349, Loss: 0.595549, Loss: 0.8420-----] ...Epoch 49, Loss: 0.6465---------------------] ...Epoch 49, Loss: 0.9237======-------------------------------] ...Epoch 49, Loss: 1.3800: 0.4648..Epoch 49, Loss: 0.5789-------------] ...Epoch 49, Loss: 0.4946-----------------------------] ...Epoch 49, Loss: 1.036149, Loss: 0.9025-----] ...Epoch 49, Loss: 0.8153---------------------] ...Epoch 49, Loss: 0.7597=======------------------------------] ...Epoch 49, Loss: 0.5313: 0.9341..Epoch 49, Loss: 1.039149, Loss: 1.1116-----] ...Epoch 49, Loss: 0.375649, Loss: 0.899949, Loss: 0.8340-----] ...Epoch 49, Loss: 0.8252---------------------] ...Epoch 49, Loss: 0.749849, Loss: 1.1707-----] ...Epoch 49, Loss: 0.903049, Loss: 1.0699-----] ...Epoch 49, Loss: 0.5640---------------------] ...Epoch 49, Loss: 1.2344=========----------------------------] ...Epoch 49, Loss: 0.4869: 0.8394..Epoch 49, Loss: 1.0045-------------] ...Epoch 49, Loss: 0.5660=----------------------------] ...Epoch 49, Loss: 0.813049, Loss: 0.6753-----] ...Epoch 49, Loss: 0.3721---------------------] ...Epoch 49, Loss: 0.9909==========---------------------------] ...Epoch 49, Loss: 0.8618: 1.6299..Epoch 49, Loss: 0.4489-------------] ...Epoch 49, Loss: 0.9365==---------------------------] ...Epoch 49, Loss: 0.573649, Loss: 0.620049, Loss: 0.7663-----] ...Epoch 49, Loss: 1.2845---------------------] ...Epoch 49, Loss: 0.945949, Loss: 0.837349, Loss: 1.0646-----] ...Epoch 49, Loss: 0.8411---------------------] ...Epoch 49, Loss: 0.751749, Loss: 1.492949, Loss: 1.0929-----] ...Epoch 49, Loss: 1.2061---------------------] ...Epoch 49, Loss: 0.5482=============------------------------] ...Epoch 49, Loss: 0.8008: 0.5032..Epoch 49, Loss: 0.4935-------------] ...Epoch 49, Loss: 0.7879=====------------------------] ...Epoch 49, Loss: 0.605549, Loss: 0.4898-----] ...Epoch 49, Loss: 0.3893---------------------] ...Epoch 49, Loss: 0.4197==============-----------------------] ...Epoch 49, Loss: 0.6399: 0.971049, Loss: 0.8882-----] ...Epoch 49, Loss: 0.784849, Loss: 0.587849, Loss: 0.661449, Loss: 0.8543-----] ...Epoch 49, Loss: 0.6388---------------------] ...Epoch 49, Loss: 1.4674================---------------------] ...Epoch 49, Loss: 0.5967: 0.7309..Epoch 49, Loss: 1.3768-------------] ...Epoch 49, Loss: 0.6922========---------------------] ...Epoch 49, Loss: 0.748249, Loss: 0.8103-----] ...Epoch 49, Loss: 1.0519=--------------------] ...Epoch 49, Loss: 0.6639=================--------------------] ...Epoch 49, Loss: 0.6692: 0.6380..Epoch 49, Loss: 0.7697-------------] ...Epoch 49, Loss: 0.8292=========--------------------] ...Epoch 49, Loss: 0.290049, Loss: 0.5907-----] ...Epoch 49, Loss: 0.5496==-------------------] ...Epoch 49, Loss: 1.1432==================-------------------] ...Epoch 49, Loss: 1.4215: 0.7287..Epoch 49, Loss: 0.842449, Loss: 0.4749-----] ...Epoch 49, Loss: 0.517349, Loss: 0.5183-----] ...Epoch 49, Loss: 0.6653===------------------] ...Epoch 49, Loss: 0.5869===================------------------] ...Epoch 49, Loss: 0.8766: 0.702749, Loss: 0.702449, Loss: 0.678449, Loss: 1.396049, Loss: 0.7167-----] ...Epoch 49, Loss: 0.6854=====----------------] ...Epoch 49, Loss: 0.9411=====================----------------] ...Epoch 49, Loss: 0.8968: 0.8017..Epoch 49, Loss: 0.5854-------------] ...Epoch 49, Loss: 1.2226==============---------------] ...Epoch 49, Loss: 0.609549, Loss: 0.510849, Loss: 1.0707-----] ...Epoch 49, Loss: 0.7434======---------------] ...Epoch 49, Loss: 0.6253======================---------------] ...Epoch 49, Loss: 0.9290: 0.3758..Epoch 49, Loss: 1.1224-------------] ...Epoch 49, Loss: 0.9257===============--------------] ...Epoch 49, Loss: 0.774949, Loss: 0.771849, Loss: 1.258349, Loss: 0.955449, Loss: 0.522749, Loss: 0.8124-----] ...Epoch 49, Loss: 0.9942========-------------] ...Epoch 49, Loss: 1.2141========================-------------] ...Epoch 49, Loss: 0.7520: 0.7801..Epoch 49, Loss: 1.2158-------------] ...Epoch 49, Loss: 0.5483================-------------] ...Epoch 49, Loss: 0.964749, Loss: 1.2644-----] ...Epoch 49, Loss: 0.5865=========------------] ...Epoch 49, Loss: 0.9526=========================------------] ...Epoch 49, Loss: 0.9337: 0.6310..Epoch 49, Loss: 1.0158=------------] ...Epoch 49, Loss: 0.4359=================------------] ...Epoch 49, Loss: 0.658149, Loss: 0.6905-----] ...Epoch 49, Loss: 0.5982==========-----------] ...Epoch 49, Loss: 0.6801==========================-----------] ...Epoch 49, Loss: 0.8591: 1.1301..Epoch 49, Loss: 0.5228==-----------] ...Epoch 49, Loss: 1.1347==================-----------] ...Epoch 49, Loss: 0.542749, Loss: 1.099149, Loss: 0.6266-----] ...Epoch 49, Loss: 0.4557===========----------] ...Epoch 49, Loss: 0.676149, Loss: 1.076349, Loss: 0.6917-----] ...Epoch 49, Loss: 2.061849, Loss: 1.1320-----] ...Epoch 49, Loss: 0.8662============---------] ...Epoch 49, Loss: 0.5913============================---------] ...Epoch 49, Loss: 0.613049, Loss: 0.546549, Loss: 0.7705-----] ...Epoch 49, Loss: 0.568849, Loss: 0.3222-----] ...Epoch 49, Loss: 0.4370==============-------] ...Epoch 49, Loss: 0.8664==============================-------] ...Epoch 49, Loss: 0.5821: 0.4002..Epoch 49, Loss: 1.0560======-------] ...Epoch 49, Loss: 1.1649======================-------] ...Epoch 49, Loss: 0.418349, Loss: 0.6101-----] ...Epoch 49, Loss: 0.5861==============-------] ...Epoch 49, Loss: 0.972749, Loss: 0.911249, Loss: 0.773549, Loss: 0.4018-----] ...Epoch 49, Loss: 1.0398================-----] ...Epoch 49, Loss: 0.7706================================-----] ...Epoch 49, Loss: 1.4616: 0.7641..Epoch 49, Loss: 0.562649, Loss: 0.515349, Loss: 0.8456=----] ...Epoch 49, Loss: 1.4185=================----] ...Epoch 49, Loss: 0.7450=================================----] ...Epoch 49, Loss: 1.0779: 0.904949, Loss: 0.6991==---] ...Epoch 49, Loss: 1.031549, Loss: 0.8365===--] ...Epoch 49, Loss: 0.5437===================--] ...Epoch 49, Loss: 0.3817===================================--] ...Epoch 49, Loss: 0.7974: 0.676949, Loss: 0.468849, Loss: 0.515749, Loss: 0.468649, Loss: 0.6707====-] ...Epoch 49, Loss: 0.815349, Loss: 1.1962=====] ...Epoch 49, Loss: 0.7343\n",
      " Epoch 49, Total loss: 0.8352\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================================] ...Epoch 50, Loss: 0.597150, Loss: 0.562250, Loss: 0.8988-----] ...Epoch 50, Loss: 0.7767---------------------] ...Epoch 50, Loss: 0.5781-------------------------------------] ...Epoch 50, Loss: 0.7768..Epoch 50, Loss: 0.5176-------------] ...Epoch 50, Loss: 1.1336-----------------------------] ...Epoch 50, Loss: 0.768850, Loss: 0.7880-----] ...Epoch 50, Loss: 1.0655---------------------] ...Epoch 50, Loss: 1.0891-------------------------------------] ...Epoch 50, Loss: 0.508650, Loss: 0.8557-----] ...Epoch 50, Loss: 0.6349---------------------] ...Epoch 50, Loss: 0.9346-------------------------------------] ...Epoch 50, Loss: 0.8055: 1.1135..Epoch 50, Loss: 1.0643-------------] ...Epoch 50, Loss: 0.4463-----------------------------] ...Epoch 50, Loss: 0.643850, Loss: 1.1159-----] ...Epoch 50, Loss: 0.5119---------------------] ...Epoch 50, Loss: 0.419450, Loss: 0.9392-----] ...Epoch 50, Loss: 0.644750, Loss: 0.6730-----] ...Epoch 50, Loss: 1.0417---------------------] ...Epoch 50, Loss: 0.647050, Loss: 0.714450, Loss: 0.6899-----] ...Epoch 50, Loss: 1.2346---------------------] ...Epoch 50, Loss: 1.0528==-----------------------------------] ...Epoch 50, Loss: 0.8587: 0.7542..Epoch 50, Loss: 0.4348-------------] ...Epoch 50, Loss: 0.6353-----------------------------] ...Epoch 50, Loss: 0.801850, Loss: 0.7437-----] ...Epoch 50, Loss: 1.1359---------------------] ...Epoch 50, Loss: 1.0623===----------------------------------] ...Epoch 50, Loss: 0.7797: 0.4609..Epoch 50, Loss: 0.9148-------------] ...Epoch 50, Loss: 0.8525-----------------------------] ...Epoch 50, Loss: 0.833050, Loss: 0.6713-----] ...Epoch 50, Loss: 0.7513---------------------] ...Epoch 50, Loss: 0.5346====---------------------------------] ...Epoch 50, Loss: 1.2124: 0.4354..Epoch 50, Loss: 1.9713-------------] ...Epoch 50, Loss: 0.4079-----------------------------] ...Epoch 50, Loss: 0.935550, Loss: 0.5209-----] ...Epoch 50, Loss: 0.5800---------------------] ...Epoch 50, Loss: 1.3969====---------------------------------] ...Epoch 50, Loss: 0.4259: 1.0342..Epoch 50, Loss: 0.9766-------------] ...Epoch 50, Loss: 0.9081-----------------------------] ...Epoch 50, Loss: 1.258150, Loss: 1.2822-----] ...Epoch 50, Loss: 0.8045---------------------] ...Epoch 50, Loss: 0.8487=====--------------------------------] ...Epoch 50, Loss: 1.2379: 1.1577..Epoch 50, Loss: 1.4347-------------] ...Epoch 50, Loss: 0.4989-----------------------------] ...Epoch 50, Loss: 0.878950, Loss: 1.0345-----] ...Epoch 50, Loss: 0.845250, Loss: 1.580150, Loss: 0.5156-----] ...Epoch 50, Loss: 0.5811---------------------] ...Epoch 50, Loss: 0.8434=======------------------------------] ...Epoch 50, Loss: 0.6724: 0.8896..Epoch 50, Loss: 1.0337-------------] ...Epoch 50, Loss: 0.6512-----------------------------] ...Epoch 50, Loss: 0.798950, Loss: 0.8605-----] ...Epoch 50, Loss: 0.8813---------------------] ...Epoch 50, Loss: 1.2998========-----------------------------] ...Epoch 50, Loss: 0.8128: 0.6682..Epoch 50, Loss: 0.5480-------------] ...Epoch 50, Loss: 0.8279-----------------------------] ...Epoch 50, Loss: 0.687450, Loss: 1.3314-----] ...Epoch 50, Loss: 0.9278---------------------] ...Epoch 50, Loss: 1.0319=========----------------------------] ...Epoch 50, Loss: 0.9199: 1.6376..Epoch 50, Loss: 0.9316-------------] ...Epoch 50, Loss: 0.7711=----------------------------] ...Epoch 50, Loss: 0.705450, Loss: 1.4566-----] ...Epoch 50, Loss: 0.9348---------------------] ...Epoch 50, Loss: 0.658650, Loss: 1.1711-----] ...Epoch 50, Loss: 0.5775---------------------] ...Epoch 50, Loss: 1.3610==========---------------------------] ...Epoch 50, Loss: 1.3074: 0.6982..Epoch 50, Loss: 1.0641-------------] ...Epoch 50, Loss: 1.2501===--------------------------] ...Epoch 50, Loss: 0.705250, Loss: 0.6215-----] ...Epoch 50, Loss: 1.1143---------------------] ...Epoch 50, Loss: 0.6900===========--------------------------] ...Epoch 50, Loss: 1.0853: 1.2527..Epoch 50, Loss: 0.8511-------------] ...Epoch 50, Loss: 0.6684===--------------------------] ...Epoch 50, Loss: 0.830350, Loss: 0.4948-----] ...Epoch 50, Loss: 1.302250, Loss: 0.348650, Loss: 0.562650, Loss: 1.582050, Loss: 1.6060-----] ...Epoch 50, Loss: 1.265750, Loss: 0.8092-----] ...Epoch 50, Loss: 0.6660---------------------] ...Epoch 50, Loss: 0.517250, Loss: 0.590350, Loss: 0.7396-----] ...Epoch 50, Loss: 0.9523---------------------] ...Epoch 50, Loss: 0.6168==============-----------------------] ...Epoch 50, Loss: 0.6735: 0.5217..Epoch 50, Loss: 0.8488-------------] ...Epoch 50, Loss: 0.6287======-----------------------] ...Epoch 50, Loss: 1.031950, Loss: 0.719950, Loss: 1.0361-----] ...Epoch 50, Loss: 0.7564---------------------] ...Epoch 50, Loss: 0.6767===============----------------------] ...Epoch 50, Loss: 0.8784: 0.5985..Epoch 50, Loss: 0.772950, Loss: 0.809950, Loss: 0.850950, Loss: 0.7398-----] ...Epoch 50, Loss: 1.0430---------------------] ...Epoch 50, Loss: 0.9409================---------------------] ...Epoch 50, Loss: 1.3572: 0.860450, Loss: 0.915450, Loss: 0.7884-----] ...Epoch 50, Loss: 1.1938=--------------------] ...Epoch 50, Loss: 0.6978=================--------------------] ...Epoch 50, Loss: 0.882450, Loss: 0.8323-----] ...Epoch 50, Loss: 0.773750, Loss: 1.1103-----] ...Epoch 50, Loss: 0.9617==-------------------] ...Epoch 50, Loss: 1.363450, Loss: 0.706950, Loss: 0.743750, Loss: 0.936850, Loss: 0.9143-----] ...Epoch 50, Loss: 0.8534===------------------] ...Epoch 50, Loss: 0.4866===================------------------] ...Epoch 50, Loss: 0.495250, Loss: 0.752450, Loss: 0.8623-----] ...Epoch 50, Loss: 1.3697====-----------------] ...Epoch 50, Loss: 0.398950, Loss: 0.6104-----] ...Epoch 50, Loss: 0.507050, Loss: 0.7017-----] ...Epoch 50, Loss: 0.803450, Loss: 1.193650, Loss: 0.608950, Loss: 0.9310-----] ...Epoch 50, Loss: 0.8971=======--------------] ...Epoch 50, Loss: 0.634350, Loss: 1.018850, Loss: 0.6941-----] ...Epoch 50, Loss: 0.3348========-------------] ...Epoch 50, Loss: 0.796850, Loss: 0.586450, Loss: 0.939650, Loss: 0.783450, Loss: 1.213050, Loss: 0.8992-----] ...Epoch 50, Loss: 0.5890==============-------] ...Epoch 50, Loss: 1.0334==============================-------] ...Epoch 50, Loss: 0.7519: 0.539150, Loss: 0.705550, Loss: 0.9702-----] ...Epoch 50, Loss: 0.909750, Loss: 0.615350, Loss: 1.1715==---] ...Epoch 50, Loss: 0.874050, Loss: 0.6554==---] ...Epoch 50, Loss: 1.3825==================---] ...Epoch 50, Loss: 0.6445===================================--] ...Epoch 50, Loss: 1.9620: 0.9005..Epoch 50, Loss: 0.6703===========--] ...Epoch 50, Loss: 0.574750, Loss: 0.5883===--] ...Epoch 50, Loss: 0.5044===================--] ...Epoch 50, Loss: 0.5633===================================--] ...Epoch 50, Loss: 0.6534: 0.8951..Epoch 50, Loss: 0.7572============-] ...Epoch 50, Loss: 0.6098============================-] ...Epoch 50, Loss: 0.864850, Loss: 1.1102====-] ...Epoch 50, Loss: 0.6475====================-] ...Epoch 50, Loss: 0.6857====================================-] ...Epoch 50, Loss: 0.9406: 0.8355..Epoch 50, Loss: 0.5445============-] ...Epoch 50, Loss: 1.3846============================-] ...Epoch 50, Loss: 0.629950, Loss: 1.0253=====] ...Epoch 50, Loss: 0.5242=====================] ...Epoch 50, Loss: 0.7388=====================================] ...Epoch 50, Loss: 1.0713\n",
      " Epoch 50, Total loss: 0.8344\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 10, Classification Report:\u001b[0m\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.32      0.43      3972\n",
      "           1       0.57      0.77      0.65      5937\n",
      "           2       0.48      0.44      0.46      2375\n",
      "\n",
      "    accuracy                           0.56     12284\n",
      "   macro avg       0.56      0.51      0.51     12284\n",
      "weighted avg       0.57      0.56      0.54     12284\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 10, Plot:\u001b[0m\n",
      "\n",
      "Figure(800x800)\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Semeval2017A_50_loss.png?modified=12345678\" width = \"600\" height = auto;>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
